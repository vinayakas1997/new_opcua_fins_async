#!/usr/bin/env python3
"""
FINS Protocol Timing Test - D0001 to D500
==========================================
This script performs timing analysis comparing single read vs multiple read operations
for PLC registers D0001 to D500.
"""

import asyncio
import sys
from datetime import datetime
import time
import csv

# Import the FINS protocol components
from OMRON_FINS_PROTOCOL.Infrastructure.udp_connection import FinsUdpConnection
from OMRON_FINS_PROTOCOL.Fins_domain.mem_address_parser import FinsAddressParser
from OMRON_FINS_PROTOCOL.components.conversion import (
    toInt16, toUInt16, WordToHex
)
from OMRON_FINS_PROTOCOL.Fins_domain.frames import FinsResponseFrame
from OMRON_FINS_PROTOCOL.exception.exception_rules import (
    FinsConnectionError, FinsTimeoutError, FinsAddressError
)

# =============================================================================
# CONFIGURATION - MODIFY THIS SECTION
# =============================================================================

# Change this to your PLC's IP address
PLC_IP = "192.168.2.2"

# Batch configuration
BATCH_SIZE = 20  # Number of addresses per batch for multiple read

# Generate addresses from D0001 to D500
def generate_test_addresses():
    """Generate D0001 to D500 addresses"""
    addresses = {}
    for i in range(1, 501):  # D0001 to D500
        addr = f"D{i:04d}"  # Format as D0001, D0002, etc.
        addresses[addr] = "INT16"
    return addresses

# Test addresses D0001 to D500
TEST_ADDRESSES = generate_test_addresses()

print(f"ğŸ“Š D0001ã‹ã‚‰D500ã¾ã§{len(TEST_ADDRESSES)}å€‹ã®ãƒ†ã‚¹ãƒˆã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")

# =============================================================================
# TEST FUNCTIONS
# =============================================================================

async def single_read_address(fins, address, data_type):
    """Read a single address and return success status and timing"""
    try:
        address_parser = FinsAddressParser()
        command_codes = fins.command_codes
        
        # Parse address to FINS format
        addr_info = address_parser.parse(address)
        
        # Determine read size based on data type
        read_size = 1  # Single word for INT16
        
        # Build command data
        command_data = bytearray(8)
        command_data[0:2] = command_codes.MEMORY_AREA_READ
        command_data[2] = addr_info['memory_type_code']
        command_data[3:5] = bytes(addr_info['offset_bytes'])
        command_data[5] = addr_info['bit_number'] if addr_info['bit_number'] else 0
        command_data[6:8] = read_size.to_bytes(2, 'big')
        
        # Build complete frame
        command_frame = fins.fins_command_frame(
            command_code=command_data,
            service_id=b'\x00'
        )
        
        # Execute with timing
        start_time = time.perf_counter()
        response = await fins.execute_fins_command_frame(command_frame)
        end_time = time.perf_counter()
        
        # Parse response
        response_frame = FinsResponseFrame()
        response_frame.from_bytes(response)
        
        if response_frame.end_code == b'\x00\x00':
            raw_data = response_frame.text
            value = toInt16(raw_data)[0]
            return True, end_time - start_time, value
        else:
            return False, end_time - start_time, None
            
    except Exception as e:
        return False, 0, None

async def multiple_read_address(fins, addresses_dict):
    """Read multiple addresses in a single command and return timing info"""
    try:
        address_parser = FinsAddressParser()
        command_codes = fins.command_codes
        
        # Build command data for multiple read
        addresses = list(addresses_dict.keys())
        
        data_part = bytearray()
        
        for address in addresses:
            addr_info = address_parser.parse(address)
            
            # Build 4-byte structure for each address:
            # Byte 1: Memory area code
            # Bytes 2-3: Address (2 bytes)
            # Byte 4: Bit position (0x00 for word access)
            area_data = bytearray(4)
            area_data[0] = addr_info['memory_type_code']      # Area code (1 byte)
            area_data[1:3] = bytes(addr_info['offset_bytes']) # Address (2 bytes)
            area_data[3] = 0x00                               # Bit position (1 byte)
            
            data_part += area_data
        
        # Build FINS command frame with 0x0104 command code
        command_frame = fins.fins_command_frame(
            command_code=command_codes.MULTIPLE_MEMORY_AREA_READ,  # 0x0104
            text=data_part,
            service_id=b'\x00'
        )
        
        # Execute with timing
        start_time = time.perf_counter()
        response = await fins.execute_fins_command_frame(command_frame)
        end_time = time.perf_counter()
        
        response_frame = FinsResponseFrame()
        response_frame.from_bytes(response)
        
        if response_frame.end_code == b'\x00\x00':
            raw_data = response_frame.text
            values = {}
            
            # Parse each address: 1 status byte + 2 data bytes (3 bytes total per address)
            for i, (address, data_type) in enumerate(addresses_dict.items()):
                start_idx = i * 3  # Each address takes 3 bytes: 1 status + 2 data
                
                # Extract status byte and data bytes
                status_byte = raw_data[start_idx:start_idx + 1]
                value_bytes = raw_data[start_idx + 1:start_idx + 3]  # Skip status byte, get 2 data bytes
                
                if data_type == "INT16":
                    value = toInt16(value_bytes)[0]
                elif data_type == "UINT16":
                    value = toUInt16(value_bytes)[0]
                else:
                    value = toInt16(value_bytes)[0]  # Default to INT16
                
                values[address] = value
            
            return True, end_time - start_time, values
        else:
            return False, end_time - start_time, None
            
    except Exception as e:
        return False, 0, None

async def batch_read_addresses(fins, addresses_dict, batch_size=20):
    """Read addresses in batches using multiple read commands"""
    try:
        total_start_time = time.perf_counter()
        all_values = {}
        total_command_time = 0
        successful_batches = 0
        failed_batches = 0
        
        # Convert addresses_dict to list for batching
        addresses_list = list(addresses_dict.items())
        total_batches = (len(addresses_list) + batch_size - 1) // batch_size  # Ceiling division
        
        print(f"ğŸ“¦ {len(addresses_list)}å€‹ã®ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’{batch_size}å€‹ãšã¤{total_batches}ãƒãƒƒãƒã§å‡¦ç†ã—ã¾ã™")
        
        # Process addresses in batches
        for batch_num in range(total_batches):
            start_idx = batch_num * batch_size
            end_idx = min(start_idx + batch_size, len(addresses_list))
            batch_addresses = dict(addresses_list[start_idx:end_idx])
            
            print(f"   ğŸ“Š ãƒãƒƒãƒ {batch_num + 1}/{total_batches} ã‚’å‡¦ç†ä¸­ ({len(batch_addresses)}å€‹ã®ã‚¢ãƒ‰ãƒ¬ã‚¹)")
            
            # Perform multiple read for this batch
            success, command_time, batch_values = await multiple_read_address(fins, batch_addresses)
            
            if success and batch_values:
                successful_batches += 1
                total_command_time += command_time
                all_values.update(batch_values)
                print(f"      âœ… ãƒãƒƒãƒ {batch_num + 1} æˆåŠŸ ({len(batch_values)}å€‹ã®å€¤)")
            else:
                failed_batches += 1
                print(f"      âŒ ãƒãƒƒãƒ {batch_num + 1} å¤±æ•—")
        
        total_end_time = time.perf_counter()
        total_execution_time = total_end_time - total_start_time
        
        return {
            'success': successful_batches > 0,
            'total_addresses': len(addresses_list),
            'addresses_read': len(all_values),
            'successful_batches': successful_batches,
            'failed_batches': failed_batches,
            'total_batches': total_batches,
            'batch_size': batch_size,
            'total_execution_time': total_execution_time,
            'total_command_time': total_command_time,
            'avg_batch_time': total_command_time / successful_batches if successful_batches > 0 else 0,
            'addresses_per_second': len(all_values) / total_execution_time if total_execution_time > 0 else 0,
            'values': all_values
        }
        
    except Exception as e:
        print(f"âŒ ãƒãƒƒãƒèª­ã¿å–ã‚Šä¾‹å¤–: {e}")
        return {
            'success': False,
            'total_addresses': len(addresses_dict),
            'addresses_read': 0,
            'successful_batches': 0,
            'failed_batches': 0,
            'total_batches': 0,
            'batch_size': batch_size,
            'total_execution_time': 0,
            'total_command_time': 0,
            'avg_batch_time': 0,
            'addresses_per_second': 0,
            'values': {}
        }

async def test_batch_read_timing(fins, addresses_dict, batch_size=20):
    """Test reading addresses in batches and measure timing"""
    print(f"ğŸ“¦ ãƒãƒƒãƒèª­ã¿å–ã‚Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ (ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size})")
    print("=" * 60)
    print(f"ğŸ“Š {len(addresses_dict)}å€‹ã®ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’{batch_size}å€‹ãšã¤ãƒãƒƒãƒã§èª­ã¿å–ã‚Šã¾ã™...")
    
    batch_results = await batch_read_addresses(fins, addresses_dict, batch_size)
    
    print("ğŸ“Š ãƒãƒƒãƒèª­ã¿å–ã‚Šçµæœ:")
    print("=" * 60)
    
    if batch_results['success']:
        print(f"âœ… {batch_results['addresses_read']}/{batch_results['total_addresses']}å€‹ã®ã‚¢ãƒ‰ãƒ¬ã‚¹ã®èª­ã¿å–ã‚Šã«æˆåŠŸã—ã¾ã—ãŸ")
        print(f"ğŸ“¦ æˆåŠŸã—ãŸãƒãƒƒãƒ: {batch_results['successful_batches']}/{batch_results['total_batches']}")
        print(f"âŒ å¤±æ•—ã—ãŸãƒãƒƒãƒ: {batch_results['failed_batches']}")
        print(f"ğŸ“ ãƒãƒƒãƒã‚µã‚¤ã‚º: ãƒãƒƒãƒã‚ãŸã‚Š{batch_results['batch_size']}å€‹ã®ã‚¢ãƒ‰ãƒ¬ã‚¹")
        print(f"â±ï¸  ç·å®Ÿè¡Œæ™‚é–“: {batch_results['total_execution_time']:.4f}ç§’")
        print(f"â±ï¸  ç·ã‚³ãƒãƒ³ãƒ‰æ™‚é–“: {batch_results['total_command_time']:.4f}ç§’")
        print(f"â±ï¸  å¹³å‡ãƒãƒƒãƒæ™‚é–“: {batch_results['avg_batch_time']:.6f}ç§’")
        print(f"ğŸ“ˆ 1ç§’ã‚ãŸã‚Šã®èª­ã¿å–ã‚Šã‚¢ãƒ‰ãƒ¬ã‚¹æ•°: {batch_results['addresses_per_second']:.2f}")
        
        # Show sample values
        if batch_results['values']:
            addr_list = list(batch_results['values'].keys())
            print(f"ğŸ“‹ ã‚µãƒ³ãƒ—ãƒ«å€¤ (æœ€åˆã®10å€‹):")
            for addr in addr_list[:10]:
                print(f"   ğŸ“Š {addr}: {batch_results['values'][addr]}")
            print(f"ğŸ“‹ ã‚µãƒ³ãƒ—ãƒ«å€¤ (æœ€å¾Œã®10å€‹):")
            for addr in addr_list[-10:]:
                print(f"   ğŸ“Š {addr}: {batch_results['values'][addr]}")
    else:
        print("âŒ ãƒãƒƒãƒèª­ã¿å–ã‚Šã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    print()
    return batch_results

async def test_single_reads_timing(fins, addresses_dict):
    """Test reading all addresses one by one and measure timing"""
    print("ğŸ” å˜ä¸€èª­ã¿å–ã‚Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    print(f"ğŸ“Š {len(addresses_dict)}å€‹ã®ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å€‹åˆ¥ã«èª­ã¿å–ã‚Šã¾ã™...")
    
    total_start_time = time.perf_counter()
    successful_reads = 0
    failed_reads = 0
    total_read_time = 0
    min_time = float('inf')
    max_time = 0
    single_values = {}  # Store values for CSV comparison
    
    # Read each address individually
    for i, (address, data_type) in enumerate(addresses_dict.items(), 1):
        success, read_time, value = await single_read_address(fins, address, data_type)
        
        if success:
            successful_reads += 1
            total_read_time += read_time
            min_time = min(min_time, read_time)
            max_time = max(max_time, read_time)
            single_values[address] = value  # Store value for CSV
            
            # Print progress every 50 reads
            if i % 50 == 0:
                print(f"   ğŸ“ˆ é€²æ—: {i}/{len(addresses_dict)} èª­ã¿å–ã‚Šå®Œäº†")
        else:
            failed_reads += 1
            single_values[address] = None  # Mark failed reads
    
    total_end_time = time.perf_counter()
    total_execution_time = total_end_time - total_start_time
    
    # Calculate statistics
    avg_read_time = total_read_time / successful_reads if successful_reads > 0 else 0
    
    print("ğŸ“Š å˜ä¸€èª­ã¿å–ã‚Šçµæœ:")
    print("=" * 60)
    print(f"âœ… æˆåŠŸã—ãŸèª­ã¿å–ã‚Š: {successful_reads}")
    print(f"âŒ å¤±æ•—ã—ãŸèª­ã¿å–ã‚Š: {failed_reads}")
    print(f"â±ï¸  ç·å®Ÿè¡Œæ™‚é–“: {total_execution_time:.4f}ç§’")
    print(f"â±ï¸  ç·èª­ã¿å–ã‚Šæ™‚é–“(åˆè¨ˆ): {total_read_time:.4f}ç§’")
    print(f"â±ï¸  å¹³å‡èª­ã¿å–ã‚Šæ™‚é–“: {avg_read_time:.6f}ç§’")
    print(f"â±ï¸  æœ€å°èª­ã¿å–ã‚Šæ™‚é–“: {min_time:.6f}ç§’")
    print(f"â±ï¸  æœ€å¤§èª­ã¿å–ã‚Šæ™‚é–“: {max_time:.6f}ç§’")
    print(f"ğŸ“ˆ 1ç§’ã‚ãŸã‚Šã®èª­ã¿å–ã‚Šæ•°: {successful_reads / total_execution_time:.2f}")
    print()
    
    return {
        'successful_reads': successful_reads,
        'failed_reads': failed_reads,
        'total_execution_time': total_execution_time,
        'total_read_time': total_read_time,
        'avg_read_time': avg_read_time,
        'min_read_time': min_time if min_time != float('inf') else 0,
        'max_read_time': max_time,
        'reads_per_second': successful_reads / total_execution_time if total_execution_time > 0 else 0,
        'values': single_values  # Include values for CSV export
    }

async def test_multiple_read_timing(fins, addresses_dict):
    """Test reading all addresses in a single command and measure timing"""
    print("ğŸ“š è¤‡æ•°èª­ã¿å–ã‚Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    print(f"ğŸ“Š {len(addresses_dict)}å€‹ã®ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’1ã¤ã®ã‚³ãƒãƒ³ãƒ‰ã§èª­ã¿å–ã‚Šã¾ã™...")
    
    total_start_time = time.perf_counter()
    
    # Perform multiple read
    success, read_time, values = await multiple_read_address(fins, addresses_dict)
    
    total_end_time = time.perf_counter()
    total_execution_time = total_end_time - total_start_time
    
    print("ğŸ“Š è¤‡æ•°èª­ã¿å–ã‚Šçµæœ:")
    print("=" * 60)
    
    if success and values is not None:
        print(f"âœ… {len(values)}å€‹ã®ã‚¢ãƒ‰ãƒ¬ã‚¹ã®èª­ã¿å–ã‚Šã«æˆåŠŸã—ã¾ã—ãŸ")
        print(f"â±ï¸  ç·å®Ÿè¡Œæ™‚é–“: {total_execution_time:.4f}ç§’")
        print(f"â±ï¸  ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œæ™‚é–“: {read_time:.6f}ç§’")
        print(f"ğŸ“ˆ 1ç§’ã‚ãŸã‚Šã®èª­ã¿å–ã‚Šã‚¢ãƒ‰ãƒ¬ã‚¹æ•°: {len(values) / total_execution_time:.2f}")
        print(f"âš¡ é€Ÿåº¦å„ªä½æ€§: ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚ãŸã‚Š{len(values) / read_time:.0f}å€é«˜é€Ÿ")
        
        # Show first 10 and last 10 values as sample
        addr_list = list(values.keys())
        print(f"ğŸ“‹ ã‚µãƒ³ãƒ—ãƒ«å€¤ (æœ€åˆã®10å€‹):")
        for addr in addr_list[:10]:
            print(f"   ğŸ“Š {addr}: {values[addr]}")
        print(f"ğŸ“‹ ã‚µãƒ³ãƒ—ãƒ«å€¤ (æœ€å¾Œã®10å€‹):")
        for addr in addr_list[-10:]:
            print(f"   ğŸ“Š {addr}: {values[addr]}")
            
        result = {
            'success': True,
            'addresses_read': len(values),
            'total_execution_time': total_execution_time,
            'command_execution_time': read_time,
            'addresses_per_second': len(values) / total_execution_time
        }
    else:
        print("âŒ è¤‡æ•°èª­ã¿å–ã‚Šã«å¤±æ•—ã—ã¾ã—ãŸ")
        result = {
            'success': False,
            'addresses_read': 0,
            'total_execution_time': total_execution_time,
            'command_execution_time': 0,
            'addresses_per_second': 0
        }
    
    print()
    return result

def compare_performance(single_results, multiple_results, batch_results=None):
    """Compare the performance of single vs batch reads"""
    print("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ")
    print("=" * 60)
    
    if single_results['successful_reads'] > 0:
        single_rate = single_results['reads_per_second']
        
        print(f"ğŸ“Š å˜ä¸€èª­ã¿å–ã‚Šæ–¹å¼:")
        print(f"   â±ï¸  ç·æ™‚é–“: {single_results['total_execution_time']:.4f}ç§’")
        print(f"   ğŸ“ˆ ãƒ¬ãƒ¼ãƒˆ: {single_rate:.2f}ã‚¢ãƒ‰ãƒ¬ã‚¹/ç§’")
        print(f"   ğŸ“Š æˆåŠŸç‡: {single_results['successful_reads'] / (single_results['successful_reads'] + single_results['failed_reads']) * 100:.1f}%")
        print()
        
        # Compare batch results if provided
        if batch_results and batch_results['success']:
            batch_rate = batch_results['addresses_per_second']
            
            print(f"ğŸ“¦ ãƒãƒƒãƒèª­ã¿å–ã‚Šæ–¹å¼:")
            print(f"   â±ï¸  ç·æ™‚é–“: {batch_results['total_execution_time']:.4f}ç§’")
            print(f"   ğŸ“ˆ ãƒ¬ãƒ¼ãƒˆ: {batch_rate:.2f}ã‚¢ãƒ‰ãƒ¬ã‚¹/ç§’")
            print(f"   ğŸ“Š ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_results['batch_size']}ã‚¢ãƒ‰ãƒ¬ã‚¹")
            print(f"   ğŸ“ˆ æˆåŠŸç‡: {batch_results['successful_batches']}/{batch_results['total_batches']} ({batch_results['successful_batches']/batch_results['total_batches']*100:.1f}%)")
            print()
            
            if single_rate > 0:
                speed_improvement = batch_rate / single_rate
                time_reduction = ((single_results['total_execution_time'] - batch_results['total_execution_time']) / single_results['total_execution_time']) * 100
                
                print(f"ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š:")
                print(f"   âš¡ é€Ÿåº¦æ”¹å–„: {speed_improvement:.1f}å€é«˜é€Ÿ")
                print(f"   â±ï¸  æ™‚é–“çŸ­ç¸®: {time_reduction:.1f}%")
                print(f"   ğŸ’° åŠ¹ç‡å‘ä¸Š: {((speed_improvement - 1) * 100):.1f}%åŠ¹ç‡çš„")
                
                if speed_improvement > 10:
                    print(f"   ğŸ† å„ªç§€: ãƒãƒƒãƒèª­ã¿å–ã‚Šã¯å¤§å¹…ã«é«˜é€Ÿã§ã™ï¼")
                elif speed_improvement > 5:
                    print(f"   ğŸ‘ è‰¯å¥½: ãƒãƒƒãƒèª­ã¿å–ã‚Šã¯è‰¯å¥½ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ã‚’ç¤ºã—ã¦ã„ã¾ã™")
                elif speed_improvement > 2:
                    print(f"   âœ… ä¸­ç¨‹åº¦: ãƒãƒƒãƒèª­ã¿å–ã‚Šã¯ä¸­ç¨‹åº¦ã«é«˜é€Ÿã§ã™")
                else:
                    print(f"   âš ï¸  æœ€å°é™: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ã¯é™å®šçš„ã§ã™")
        else:
            print("âŒ ãƒãƒƒãƒèª­ã¿å–ã‚Šãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ãŸã‹ã€åˆ©ç”¨ã§ãã¾ã›ã‚“")
    else:
        print("âŒ æ¯”è¼ƒã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ - å˜ä¸€èª­ã¿å–ã‚Šãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
    
    print()

def create_data_verification_csv(single_results, batch_results, default_filename="data_500.csv"):
    """Create a CSV file to compare values from both reading methods"""
    print("ğŸ“ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­...")
    print("=" * 60)
    current_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{current_timestamp}_{default_filename}"
    try:
        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            
            # Write header
            writer.writerow(['plc_reg', 'method_1', 'method_2'])
            
            # Get all addresses (should be the same for both methods)
            all_addresses = set()
            if 'values' in single_results:
                all_addresses.update(single_results['values'].keys())
            if batch_results.get('values'):
                all_addresses.update(batch_results['values'].keys())
            
            # Sort addresses for consistent ordering
            sorted_addresses = sorted(all_addresses, key=lambda x: int(x[1:]))  # Sort by numeric part
            
            # Write data rows
            matches = 0
            mismatches = 0
            single_missing = 0
            batch_missing = 0
            
            for address in sorted_addresses:
                single_value = single_results.get('values', {}).get(address, 'N/A')
                batch_value = batch_results.get('values', {}).get(address, 'N/A')
                
                # Convert None values to 'FAILED' for better readability
                if single_value is None:
                    single_value = 'FAILED'
                    single_missing += 1
                if batch_value is None:
                    batch_value = 'FAILED'
                    batch_missing += 1
                
                # Count matches/mismatches
                if single_value != 'N/A' and batch_value != 'N/A' and single_value != 'FAILED' and batch_value != 'FAILED':
                    if single_value == batch_value:
                        matches += 1
                    else:
                        mismatches += 1
                
                writer.writerow([address, single_value, batch_value])
        
        print(f"âœ… CSVãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã¾ã—ãŸï¼")
        print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚µãƒãƒªãƒ¼:")
        print(f"   ğŸ“‹ ç·ã‚¢ãƒ‰ãƒ¬ã‚¹æ•°: {len(sorted_addresses)}")
        print(f"   âœ… ä¸€è‡´ã™ã‚‹å€¤: {matches}")
        print(f"   âŒ ä¸ä¸€è‡´ã®å€¤: {mismatches}")
        print(f"   ğŸš« å˜ä¸€èª­ã¿å–ã‚Šå¤±æ•—: {single_missing}")
        print(f"   ğŸš« ãƒãƒƒãƒèª­ã¿å–ã‚Šå¤±æ•—: {batch_missing}")
        
        if mismatches == 0:
            print(f"   ğŸ‰ å®Œç’§: èª­ã¿å–ã‚Šã«æˆåŠŸã—ãŸã™ã¹ã¦ã®å€¤ãŒä¸¡æ–¹ã®æ–¹å¼ã§ä¸€è‡´ã—ã¦ã„ã¾ã™ï¼")
        elif mismatches > 0:
            print(f"   âš ï¸  è­¦å‘Š: {mismatches}å€‹ã®å€¤ãŒæ–¹å¼é–“ã§ç•°ãªã‚Šã¾ã™ - PLCãƒ‡ãƒ¼ã‚¿ã®å®‰å®šæ€§ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        
        print(f"   ğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å…ˆ: {filename}")
        print()
        
        return True
        
    except Exception as e:
        print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return False


async def main():
    """Main test function"""
    print("ğŸš€ FINSãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ - D0001ã‹ã‚‰D500")
    print("=" * 60)
    print(f"ğŸŒ PLC IPã‚¢ãƒ‰ãƒ¬ã‚¹: {PLC_IP}")
    print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆã‚¢ãƒ‰ãƒ¬ã‚¹: {len(TEST_ADDRESSES)}å€‹ (D0001ã‹ã‚‰D500)")
    print(f"â° ãƒ†ã‚¹ãƒˆé–‹å§‹: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    print()
    
    fins = None
    try:
        # Initialize connection
        print("ğŸ”Œ FINS UDPæ¥ç¶šã‚’åˆæœŸåŒ–ä¸­...")
        fins = FinsUdpConnection(PLC_IP, debug=False)  # Disable debug for timing tests
        await fins.connect()
        print("âœ… æ¥ç¶šã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸ")
        print()
        
        # Test 1: Single reads timing
        print("ğŸ” ãƒ•ã‚§ãƒ¼ã‚º1: å˜ä¸€èª­ã¿å–ã‚Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ")
        print("=" * 60)
        single_results = await test_single_reads_timing(fins, TEST_ADDRESSES)
        
        # Test 2: Batch read timing
        print("ğŸ“¦ ãƒ•ã‚§ãƒ¼ã‚º2: ãƒãƒƒãƒèª­ã¿å–ã‚Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ")
        print("=" * 60)
        batch_results = await test_batch_read_timing(fins, TEST_ADDRESSES, BATCH_SIZE)
        
        # Compare performance
        compare_performance(single_results, None, batch_results)
        
        # Final summary
        print("ğŸ“Š æœ€çµ‚ã‚µãƒãƒªãƒ¼")
        print("=" * 60)
        print(f"ğŸ“‹ ãƒ†ã‚¹ãƒˆã—ãŸç·ã‚¢ãƒ‰ãƒ¬ã‚¹æ•°: {len(TEST_ADDRESSES)}")
        print(f"â° ãƒ†ã‚¹ãƒˆå®Œäº†: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        if single_results['successful_reads'] > 0:
            print("ğŸ‰ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
            
        
        # Create CSV file for data verification
        print("ğŸ“ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼")
        print("=" * 60)
        csv_success = create_data_verification_csv(single_results, batch_results, "data_500.csv")
        
        if csv_success:
            print("âœ… ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼CSVãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã¾ã—ãŸ")
        else:
            print("âŒ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼CSVã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            
    except FinsConnectionError as e:
        print(f"ğŸš¨ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        print("ğŸ’¡ ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
        print("   - PLC IPã‚¢ãƒ‰ãƒ¬ã‚¹ãŒæ­£ã—ã„ã‹")
        print("   - PLCãŒé›»æºã‚ªãƒ³ã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«æ¥ç¶šã•ã‚Œã¦ã„ã‚‹ã‹")
        print("   - ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«ãŒUDPãƒãƒ¼ãƒˆ9600ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ã¦ã„ãªã„ã‹")
        
    except FinsTimeoutError as e:
        print(f"â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print("ğŸ’¡ PLCãŒãƒ“ã‚¸ãƒ¼çŠ¶æ…‹ã‹ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒé…ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        
    finally:
        if fins:
            await fins.disconnect()
            print("ğŸ”Œ æ¥ç¶šã‚’é–‰ã˜ã¾ã—ãŸ")
        
        print(f"â° ãƒ†ã‚¹ãƒˆå®Œäº†: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    print("FINSãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™...")
    print("Ctrl+Cã§ä¸­æ–­ã§ãã¾ã™")
    print()
    
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ›‘ ãƒ†ã‚¹ãƒˆãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\nğŸ’¥ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)